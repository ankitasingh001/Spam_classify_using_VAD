{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN based-Model Training and Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTYKIld62l8h"
      },
      "source": [
        "### Load Preprocessed data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9yphETQitsk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wpSiNd422n4",
        "outputId": "e229a925-03ff-4bc0-fadf-c0d5198cb214"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoMwPJut27_1"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os,sys\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-A_SBkS3E3O"
      },
      "source": [
        "ROOT_PATH='./drive/MyDrive/ASR_Project_Shared/'\n",
        "\n",
        "## Creating a softlink to drive root, easy for relative addressing\n",
        "\n",
        "## Guys \n",
        "\n",
        "# nb_path = './metadata_multi_clap_noise_marathi_bingte2.csv.pkl'\n",
        "# os.symlink(ROOT_PATH+'metadata_multi_clap_noise_marathi_bingte2.csv.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "# nb_path = './metadata_allspeech_noisyspeech_spamfiles.csv'\n",
        "# os.symlink(ROOT_PATH+'metadata_allspeech_spamfiles.csv', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "nb_path = './final_data'\n",
        "os.symlink(ROOT_PATH+'final_data', nb_path)\n",
        "sys.path.insert(0, nb_path) \n",
        "\n",
        "nb_path = './final_pkl'\n",
        "os.symlink(ROOT_PATH+'final_pkl', nb_path)\n",
        "sys.path.insert(0, nb_path) \n",
        "\n",
        "\n",
        "# nb_path = './metadata_multi_clap_noise_marathi_bingte2.csv'\n",
        "# os.symlink(ROOT_PATH+'metadata_multi_clap_noise_marathi_bingte2.csv', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "# nb_path = './metadata_denoised.csv'\n",
        "# os.symlink(ROOT_PATH+'metadata_denoised.csv', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "# nb_path = './metadata_allspeech_spamfiles_RNN.pkl'\n",
        "# os.symlink(ROOT_PATH+'metadata_allspeech_spamfiles_RNN.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "\n",
        "nb_path = './metadata_multi_clap_noise_marathi_bingte2_RNN.pkl'\n",
        "os.symlink(ROOT_PATH+'metadata_multi_clap_noise_marathi_bingte2_RNN.pkl', nb_path)\n",
        "sys.path.insert(0, nb_path) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf5V84jXiyH6"
      },
      "source": [
        "# !rm metadata_allspeech_spamfiles.pkl\n",
        "# !rm metadata_multi_clap_noise_marathi_bingte2.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAXXe1rsmDmm"
      },
      "source": [
        "# nb_path = './metadata_allspeech_spamfiles.csv.pkl'\n",
        "# os.symlink(ROOT_PATH+'metadata_allspeech_spamfiles.csv.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) \n",
        "\n",
        "\n",
        "# nb_path = './metadata_multi_clap_noise_marathi_bingte2.csv.pkl'\n",
        "# os.symlink(ROOT_PATH+'metadata_multi_clap_noise_marathi_bingte2.csv.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwP0d1IEscd5"
      },
      "source": [
        "# !rm rnn_train.pkl\n",
        "# nb_path = './rnn_train.pkl'\n",
        "# os.symlink(ROOT_PATH+'rnn_train.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuUIcOgRXt9m"
      },
      "source": [
        "# !rm rnn_train_tot.pkl\n",
        "# nb_path = './rnn_train_tot.pkl'\n",
        "# os.symlink(ROOT_PATH+'rnn_train_tot.pkl', nb_path)\n",
        "# sys.path.insert(0, nb_path) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUq_MaQI2l8i"
      },
      "source": [
        "# # retrieve the preprocessed data from previous notebook\n",
        "\n",
        "# %store -r x_train \n",
        "# %store -r x_test \n",
        "# %store -r y_train \n",
        "# %store -r y_test \n",
        "# %store -r yy \n",
        "# %store -r le\n",
        "\n",
        "import pickle\n",
        "featuresdf =  pickle.load( open( \"./final_pkl/RNN/normal/train_metadata_speech{all_clap}_noise{all_clap+noiseclips}.pkl\", \"rb\" ) )\n",
        "\n",
        "#featuresdf = featuresdf.sample(frac=1).reset_index(drop=True)\n",
        "features_marathidf = pickle.load( open( \"./final_pkl/RNN/normal/test_metadata_speech{all_clap}_noise{qut+spam} - test_metadata_speech{all_clap}_noise{qut+spam}.pkl\", \"rb\" ) )\n",
        "#features_marathidf = features_marathidf.sample(frac=1).reset_index(drop=True)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "featuresdf = featuresdf.sample(frac=1).reset_index(drop=True)\n",
        "featuresdf = featuresdf.sample(frac=1).reset_index(drop=True)\n",
        "featuresdf = featuresdf.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "features_marathidf = features_marathidf.sample(frac=1).reset_index(drop=True)\n",
        "features_marathidf = features_marathidf.sample(frac=1).reset_index(drop=True)\n",
        "features_marathidf = features_marathidf.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "# split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
        "\n",
        "x_train = X\n",
        "y_train = yy\n",
        "\n",
        "\n",
        "X = np.array(features_marathidf.feature.tolist())\n",
        "y = np.array(features_marathidf.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "\n",
        "x_test = X\n",
        "y_test = yy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIXFHurWTr_f"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "filter_size = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7he0aieFqjQ"
      },
      "source": [
        "#RNN model \n",
        "\n",
        "\n",
        "#Create Keras Model\n",
        "## Expecting data of shape:  ( batch,seq(200),feat(40) )\n",
        "seq_len = 200\n",
        "feat_size = 40\n",
        "num_classes = 2\n",
        "def create_RNN_Model():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, batch_input_shape=(None,seq_len,feat_size), return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.adam(), metrics=['accuracy'])\n",
        "    # model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') \n",
        "    # print(model.summary())\n",
        "\n",
        "    # model.fit(x_train, y_train, batch_size=30, epochs=10, verbose=1)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzPKEiHBLpcC"
      },
      "source": [
        "try:\n",
        "    del model\n",
        "except:\n",
        "    print(\"Model doesn't exist\")\n",
        "model = create_RNN_Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQsDSTba2l8l"
      },
      "source": [
        "### Compiling the model \n",
        "\n",
        "For compiling our model, we will use the following three parameters: \n",
        "\n",
        "* Loss function - we will use `categorical_crossentropy`. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
        "\n",
        "* Metrics - we will use the `accuracy` metric which will allow us to view the accuracy score on the validation data when we train the model. \n",
        "\n",
        "* Optimizer - here we will use `adam` which is a generally good optimizer for many use cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq4sM_sx2l8l"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6wKPI2U2l8m",
        "outputId": "9d940c4b-fc94-40ba-b7de-fff42c99867b"
      },
      "source": [
        "# Display model architecture summary \n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               86528     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 86,786\n",
            "Trainable params: 86,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Pre-training accuracy: 70.7602%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p5vRlxN2l8m"
      },
      "source": [
        "### Training \n",
        "\n",
        "Here we will train the model. \n",
        "\n",
        "We will start with 100 epochs which is the number of times the model will cycle through the data. The model will improve on each cycle until it reaches a certain point. \n",
        "\n",
        "We will also start with a low batch size, as having a large batch size can reduce the generalisation ability of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKakbbXF2l8n",
        "outputId": "e14881b5-2ceb-43df-efaa-450cdeaabba1"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 2\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "# model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "141/141 [==============================] - 26s 168ms/step - loss: 0.0385 - accuracy: 0.9933 - val_loss: 1.3047 - val_accuracy: 0.8090\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.30472, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 24s 168ms/step - loss: 3.0519e-04 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.8090\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.30472\n",
            "Training completed in time:  0:00:49.326387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lReATZ52l8n"
      },
      "source": [
        "### Test the model \n",
        "\n",
        "Here we will review the accuracy of the model on both the training and test data sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn1g4GK22l8o",
        "outputId": "18510b4e-791c-42bf-a56b-77ca63cc5a30"
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  0.808966875076294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI5nDAs-2l8o"
      },
      "source": [
        "The initial Training and Testing accuracy scores are quite high. As there is not a great difference between the Training and Test scores (~5%) this suggests that the model has not suffered from overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW5wFXSNiO1T"
      },
      "source": [
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels):\n",
        "    \"\"\"\n",
        "    plots the confusion matrix\n",
        "    \"\"\"\n",
        "    matrix = confusion_matrix(y_true, y_pred)    \n",
        "    fig, ax = plt.subplots(figsize=(4,3))\n",
        "    plt.imshow(matrix)\n",
        "    ax.set_xticks(range(len(labels)));\n",
        "    ax.set_xticklabels(labels, rotation=0)\n",
        "    ax.set_yticks(range(len(labels)));\n",
        "    ax.set_yticklabels(labels)\n",
        "    max_confusions = 0\n",
        "    confused_classes = (-1, -1)\n",
        "    for i, true_label in enumerate(matrix):\n",
        "        for j, predicted_label in enumerate(true_label):\n",
        "            text = ax.text(j, i, matrix[i, j],\n",
        "                        ha=\"center\", va=\"center\", color=\"r\");\n",
        "    plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "    plt.title(\"Confusion Matrix\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGC951vXiMTh",
        "outputId": "ef06492b-7e41-4ecc-db54-ffcf25501b13"
      },
      "source": [
        "y_pred_ = model.predict(x_test, use_multiprocessing=True, workers=6, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 3s 64ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "FOEOv7G8iNAA",
        "outputId": "cbe2a6e6-be8d-40ab-816c-dd428cacddcd"
      },
      "source": [
        "y_pred = np.argmax(y_pred_, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "#labels = []_\n",
        "labels =['spam','not spam']\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ufJ3Z94m9DS"
      },
      "source": [
        "model.save('trained_rnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spBAT5Pp2l8p"
      },
      "source": [
        "### Predictions  \n",
        "\n",
        "Here we will build a method which will allow us to test the models predictions on a specified audio .wav file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0qrtUu6nFny"
      },
      "source": [
        "import keras\n",
        "magic = keras.models.load_model('trained_rnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD63Odo82l8p"
      },
      "source": [
        "import librosa \n",
        "import numpy as np \n",
        "\n",
        "# def extract_feature(file_name):\n",
        "   \n",
        "#     try:\n",
        "#         audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "#         mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
        "#         mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "        \n",
        "#     except Exception as e:\n",
        "#         print(\"Error encountered while parsing file: \", file)\n",
        "#         return None, None\n",
        "\n",
        "#     return np.array([mfccsscaled])\n",
        "\n",
        "\n",
        "\n",
        "seq_len = 200\n",
        "def extract_feature(file_name):\n",
        "   \n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        # mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "        \n",
        "        to_pad = mfccs[:,:seq_len]\n",
        "        v = max(0, (seq_len-to_pad.shape[-1]))\n",
        "        mfccsscaled = np.pad(to_pad,((0,0),(0,v))).T\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file)\n",
        "        return None \n",
        "     \n",
        "    return np.array([mfccsscaled])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDyRgAv2l8q"
      },
      "source": [
        "def print_prediction(file_name):\n",
        "    prediction_feature = extract_feature(file_name) \n",
        "\n",
        "    predicted_vector = magic.predict_classes(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(predicted_vector) \n",
        "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = magic.predict_proba(prediction_feature) \n",
        "    predicted_proba = predicted_proba_vector[0]\n",
        "    for i in range(len(predicted_proba)): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISOeVR-B2l8q"
      },
      "source": [
        "### Validation \n",
        "\n",
        "#### Test with sample data \n",
        "\n",
        "Initial sainity check to verify the predictions using a subsection of the sample audio files we explored in the first notebook. We expect the bulk of these to be classified correctly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsDKHUfK2l8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09227c30-29c7-4cde-a44c-b3f5b490b97d"
      },
      "source": [
        "# Class: Air Conditioner\n",
        "\n",
        "filename = 'final_data/noise/CAFE-CAFE-1_trim_5s_505.wav' \n",
        "print_prediction(filename) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The predicted class is: 1 \n",
            "\n",
            "0 \t\t :  0.00012945652997586876153945922852\n",
            "1 \t\t :  0.99987053871154785156250000000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kf4ymki3UpE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}